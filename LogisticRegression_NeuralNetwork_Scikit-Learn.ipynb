{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KubnO2egumeN"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXR0qyJ-uTpC"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data = load_digits()\n",
        "print(data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FfgysTkuTpC"
      },
      "source": [
        "# Data shape & statistics\n",
        "print(\"Data: \", data['data'].shape)\n",
        "print(\"Label:\", data['target'].shape)\n",
        "\n",
        "import numpy as np\n",
        "for c in range(10):\n",
        "  print('Class', c, 'Number:', np.sum(data['target']==c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG1dHr4CuTpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "5fee7ef8-b0e9-44dd-a7ec-f6b0864ef701",
        "collapsed": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for c in range(10):\n",
        "  i = 0\n",
        "  while(1):\n",
        "    if data['target'][i]==c:\n",
        "      plt.subplot(2,5,c+1)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(data['data'][i].reshape(8,8), cmap = plt.cm.gray_r)\n",
        "      plt.title(c)\n",
        "      break\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeX7JqhuTpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9989fa59-7fb4-4c17-d839-daa712e88844"
      },
      "source": [
        "test_indices, train_indices = [],[]\n",
        "num = [0] * 10 #class counting array\n",
        "for i in range(len(data['target'])):\n",
        "  if num[data['target'][i]] < 20: #test data 뽑는 과정\n",
        "    test_indices.append(i)\n",
        "    num[data['target'][i]] += 1\n",
        "  else:\n",
        "    train_indices.append(i)\n",
        "\n",
        "train_data = data['data'][train_indices]\n",
        "train_target = data['target'][train_indices]\n",
        "\n",
        "test_data = data['data'][test_indices]\n",
        "test_target = data['target'][test_indices]\n",
        "\n",
        "print(test_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 64)\n",
            "(1597, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie567PVduTpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2127c6-5162-4b35-c621-71cae09b89d0"
      },
      "source": [
        "train_data23 = train_data[(train_target == 2) | (train_target == 3)]\n",
        "train_target23 = train_target[(train_target == 2) | (train_target == 3)]\n",
        "test_data23 = test_data[(test_target == 2) | (test_target == 3)]\n",
        "test_target23 = test_target[(test_target == 2) | (test_target == 3)]\n",
        "\n",
        "print(test_data23.shape)\n",
        "print(train_data23.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 64)\n",
            "(320, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ci9vgU5uTpE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag') # backprop 안하는 모델\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter= 1000) #backprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etwr4biEuTpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac915ecf-aff2-4b83-f455-c56799ee87c9"
      },
      "source": [
        "LR = LogisticRegression(max_iter=1, solver='sag')\n",
        "LR.fit(train_data23, train_target23)\n",
        "\n",
        "train_predict23 = LR.predict(train_data23)\n",
        "test_predict23 = LR.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23 = np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_target     : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3 3 3 3 2 2 2 2 3 2 3 2 3 3 2 2 2 2\n",
            " 3 3 3]\n",
            "test_prediction : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 3 3 2 3 3 3 3 2 2 2 2 3 2 3 2 3 3 2 2 2 2\n",
            " 3 3 3]\n",
            "train_acc : 0.990625\n",
            "test_acc  : 0.975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6DMzuxRuTpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056519d7-2195-4ef5-8ca8-a906b9691981"
      },
      "source": [
        "NN23 = MLPClassifier(hidden_layer_sizes = (10), activation = 'relu', learning_rate_init = 0.01, max_iter = 1)\n",
        "NN23.fit(train_data23, train_target23)\n",
        "\n",
        "train_predict23 = NN23.predict(train_data23)\n",
        "test_predict23 = NN23.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23 = np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_target     : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3 3 3 3 2 2 2 2 3 2 3 2 3 3 2 2 2 2\n",
            " 3 3 3]\n",
            "test_prediction : [2 3 3 2 3 2 2 2 2 2 2 3 2 2 3 2 2 2 3 2 3 2 3 3 2 2 3 2 3 2 3 2 2 3 3 3 3\n",
            " 2 2 2]\n",
            "train_acc : 0.33125\n",
            "test_acc  : 0.35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGiSsaIKuTpF"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "joblib.dump(NN23, 'models/NN23.joblib') \n",
        "\n",
        "NN23_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "train_predict23 = NN23_load.predict(train_data23)\n",
        "test_predict23 = NN23_load.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23= np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NA25EGYuTpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feccb813-3e0a-4143-a9c2-482af277ac99"
      },
      "source": [
        "NN = MLPClassifier(hidden_layer_sizes = (512, 256, 256), activation = 'relu', learning_rate_init = 0.001, max_iter = 50)\n",
        "NN.fit(train_data, train_target)\n",
        "\n",
        "train_predict = NN.predict(train_data)\n",
        "\n",
        "train_acc = np.sum(train_target == train_predict) / len(train_target)\n",
        "\n",
        "print(\"train_acc :\", train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQud1OhYuTpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a979eff-b5d8-4df6-8afc-5363f6fe1223"
      },
      "source": [
        "joblib.dump(NN, 'models/NN.joblib') \n",
        "NN_load = joblib.load('models/NN.joblib') \n",
        "\n",
        "test_predict = NN.predict(test_data)\n",
        "test_acc = np.sum(test_target == test_predict) / len(test_target)\n",
        "\n",
        "print(\"test_acc :\", test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc : 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R7BMd5YuTpG"
      },
      "source": [
        "먼저, Hidden layer의 개수, 그리고 unit의 개수가 충분하지 않다고 판단되어 layer 및 unit 개수를 계속 늘려보면서 정확도를 비교해보았습니다. # of layers를 1개, 2개, 3개, 4개 등으로 늘려보았고,  # of units는 16, 32, 64, 128, 256, 512, 1024등으로 바꿔가면서 각 조합별로 10번의 시행을 해보았습니다.  # of layers는 3개, # of units는 (512, 256, 256)일 때 평균적으로 가장 좋은 정확도를 보였습니다. 두 hyperparameter의 숫자가 너무 클 때, training accuracy는 100%가 나왔지만, validation accuracy는 변동도 크고, 원하는 정확도 만큼 나오지 않았습니다. training data에 대해 Overfitting이 일어났다고 판단했습니다.\n",
        "\n",
        "\n",
        "그 다음, learning rate를 0.1부터 0.01, 0.001, 0.0001 등으로 변화시키면서 시행해보았습니다. (논문을 찾아보니 learning rate를 지수꼴로 다양하게 테스트해보는게 좋다는 언급이 많았습니다.) 여러 번 테스트해보니 시행마다 정확도 차이가 많이 났는데, 0.001일 때 가장 그 차이가 적었고, 정확도 역시 크게 나왔습니다.\n",
        "\n",
        "\n",
        "마지막으로 iteration 횟수를 조절해보았습니다. max_iter 역시 overfitting 및 underfitting에 큰 영향을 주는 요소입니다. 위에서 결정한 hyperparameters로 시행을 돌려보니 training accuracy는 계속해서 100%가 나왔지만, validation accuracy는 95% 정도가 나왔습니다. 따라서, training accuracy가 크게 떨어지지 않는 선에서, max_iter변수를 1000부터 500, 100, 50 등으로 계속 줄여나가보았습니다.(Overfitting 방지를 위해) max_iter = 40일 때 가장 좋은 정확도를 계속해서 보여주었습니다.\n",
        "\n",
        "이렇게 # of layers, # of units, learning rate, max_iteration 이 4가지의 hyperparameter tuning을 통해 정확도 0.98을 나타내는 모델을 만들 수 있었습니다."
      ]
    }
  ]
}